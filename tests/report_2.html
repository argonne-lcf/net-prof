<html><head><title>Net-Prof Summary Report</title>
<style>
body { font-family: sans-serif; padding: 2em; }
table { border-collapse: collapse; margin: 1em 0; width: 100%; }
th, td { border: 1px solid #ccc; padding: 0.5em; text-align: left; }
th { background-color: #eee; }
</style></head><body>
<h1>Net-Prof Summary</h1>
<h2>Total Non-zero Diffs: 1 / 15120</h2>
<details open>
<summary><h2>Top 20 Diffs by Interface (Charts)</h2></summary>
<h3>Interface 1</h3>
<img src='charts/iface1.png' style='width:100%; max-width:800px;'><br><br>
<h3>Interface 2</h3>
<img src='charts/iface2.png' style='width:100%; max-width:800px;'><br><br>
<h3>Interface 3</h3>
<img src='charts/iface3.png' style='width:100%; max-width:800px;'><br><br>
<h3>Interface 4</h3>
<img src='charts/iface4.png' style='width:100%; max-width:800px;'><br><br>
<h3>Interface 5</h3>
<img src='charts/iface5.png' style='width:100%; max-width:800px;'><br><br>
<h3>Interface 6</h3>
<img src='charts/iface6.png' style='width:100%; max-width:800px;'><br><br>
<h3>Interface 7</h3>
<img src='charts/iface7.png' style='width:100%; max-width:800px;'><br><br>
<h3>Interface 8</h3>
<img src='charts/iface8.png' style='width:100%; max-width:800px;'><br><br>
</details>
<h3>Non-zero Diffs by Interface</h3>
<table><tr><th>Interface</th><th>Non-zero Count</th></tr>
<tr><td>Interface 1</td><td>1 / 1890</td></tr>
<tr><td>Interface 2</td><td>0 / 1890</td></tr>
<tr><td>Interface 3</td><td>0 / 1890</td></tr>
<tr><td>Interface 4</td><td>0 / 1890</td></tr>
<tr><td>Interface 5</td><td>0 / 1890</td></tr>
<tr><td>Interface 6</td><td>0 / 1890</td></tr>
<tr><td>Interface 7</td><td>0 / 1890</td></tr>
<tr><td>Interface 8</td><td>0 / 1890</td></tr>
</table>
<details>
<h3>Top 20 Diffs per Interface (Raw Table)</h3>
<h4>Interface 1</h4>
<table><tr><th>Rank</th><th>Metric ID</th><th>Metric Name</th><th>Diff</th></tr>
<tr><td>1</td><td>17</td><td>atu_cache_evictions</td><td>100000</td></tr>
<tr><td>2</td><td>1</td><td>atu_ats_dynamic_state_change_cntr</td><td>0</td></tr>
<tr><td>3</td><td>2</td><td>atu_ats_inval_cntr</td><td>0</td></tr>
<tr><td>4</td><td>3</td><td>atu_ats_prs_odp_latency_0</td><td>0</td></tr>
<tr><td>5</td><td>4</td><td>atu_ats_prs_odp_latency_1</td><td>0</td></tr>
<tr><td>6</td><td>5</td><td>atu_ats_prs_odp_latency_2</td><td>0</td></tr>
<tr><td>7</td><td>6</td><td>atu_ats_prs_odp_latency_3</td><td>0</td></tr>
<tr><td>8</td><td>7</td><td>atu_at_stall_ccp</td><td>0</td></tr>
<tr><td>9</td><td>8</td><td>atu_at_stall_no_ptid</td><td>0</td></tr>
<tr><td>10</td><td>9</td><td>atu_at_stall_np_cdts</td><td>0</td></tr>
<tr><td>11</td><td>10</td><td>atu_at_stall_tarb_arb</td><td>0</td></tr>
<tr><td>12</td><td>11</td><td>atu_ats_trans_err</td><td>0</td></tr>
<tr><td>13</td><td>12</td><td>atu_ats_trans_latency_0</td><td>0</td></tr>
<tr><td>14</td><td>13</td><td>atu_ats_trans_latency_1</td><td>0</td></tr>
<tr><td>15</td><td>14</td><td>atu_ats_trans_latency_2</td><td>0</td></tr>
<tr><td>16</td><td>15</td><td>atu_ats_trans_latency_3</td><td>0</td></tr>
<tr><td>17</td><td>16</td><td>atu_atucq_inval_cntr</td><td>0</td></tr>
<tr><td>18</td><td>18</td><td>atu_cache_hit_base_page_size_0</td><td>0</td></tr>
<tr><td>19</td><td>19</td><td>atu_cache_hit_base_page_size_1</td><td>0</td></tr>
<tr><td>20</td><td>20</td><td>atu_cache_hit_base_page_size_2</td><td>0</td></tr>
</table>
<h4>Interface 2</h4>
<table><tr><th>Rank</th><th>Metric ID</th><th>Metric Name</th><th>Diff</th></tr>
<tr><td>1</td><td>1</td><td>atu_ats_dynamic_state_change_cntr</td><td>0</td></tr>
<tr><td>2</td><td>2</td><td>atu_ats_inval_cntr</td><td>0</td></tr>
<tr><td>3</td><td>3</td><td>atu_ats_prs_odp_latency_0</td><td>0</td></tr>
<tr><td>4</td><td>4</td><td>atu_ats_prs_odp_latency_1</td><td>0</td></tr>
<tr><td>5</td><td>5</td><td>atu_ats_prs_odp_latency_2</td><td>0</td></tr>
<tr><td>6</td><td>6</td><td>atu_ats_prs_odp_latency_3</td><td>0</td></tr>
<tr><td>7</td><td>7</td><td>atu_at_stall_ccp</td><td>0</td></tr>
<tr><td>8</td><td>8</td><td>atu_at_stall_no_ptid</td><td>0</td></tr>
<tr><td>9</td><td>9</td><td>atu_at_stall_np_cdts</td><td>0</td></tr>
<tr><td>10</td><td>10</td><td>atu_at_stall_tarb_arb</td><td>0</td></tr>
<tr><td>11</td><td>11</td><td>atu_ats_trans_err</td><td>0</td></tr>
<tr><td>12</td><td>12</td><td>atu_ats_trans_latency_0</td><td>0</td></tr>
<tr><td>13</td><td>13</td><td>atu_ats_trans_latency_1</td><td>0</td></tr>
<tr><td>14</td><td>14</td><td>atu_ats_trans_latency_2</td><td>0</td></tr>
<tr><td>15</td><td>15</td><td>atu_ats_trans_latency_3</td><td>0</td></tr>
<tr><td>16</td><td>16</td><td>atu_atucq_inval_cntr</td><td>0</td></tr>
<tr><td>17</td><td>17</td><td>atu_cache_evictions</td><td>0</td></tr>
<tr><td>18</td><td>18</td><td>atu_cache_hit_base_page_size_0</td><td>0</td></tr>
<tr><td>19</td><td>19</td><td>atu_cache_hit_base_page_size_1</td><td>0</td></tr>
<tr><td>20</td><td>20</td><td>atu_cache_hit_base_page_size_2</td><td>0</td></tr>
</table>
<h4>Interface 3</h4>
<table><tr><th>Rank</th><th>Metric ID</th><th>Metric Name</th><th>Diff</th></tr>
<tr><td>1</td><td>1</td><td>atu_ats_dynamic_state_change_cntr</td><td>0</td></tr>
<tr><td>2</td><td>2</td><td>atu_ats_inval_cntr</td><td>0</td></tr>
<tr><td>3</td><td>3</td><td>atu_ats_prs_odp_latency_0</td><td>0</td></tr>
<tr><td>4</td><td>4</td><td>atu_ats_prs_odp_latency_1</td><td>0</td></tr>
<tr><td>5</td><td>5</td><td>atu_ats_prs_odp_latency_2</td><td>0</td></tr>
<tr><td>6</td><td>6</td><td>atu_ats_prs_odp_latency_3</td><td>0</td></tr>
<tr><td>7</td><td>7</td><td>atu_at_stall_ccp</td><td>0</td></tr>
<tr><td>8</td><td>8</td><td>atu_at_stall_no_ptid</td><td>0</td></tr>
<tr><td>9</td><td>9</td><td>atu_at_stall_np_cdts</td><td>0</td></tr>
<tr><td>10</td><td>10</td><td>atu_at_stall_tarb_arb</td><td>0</td></tr>
<tr><td>11</td><td>11</td><td>atu_ats_trans_err</td><td>0</td></tr>
<tr><td>12</td><td>12</td><td>atu_ats_trans_latency_0</td><td>0</td></tr>
<tr><td>13</td><td>13</td><td>atu_ats_trans_latency_1</td><td>0</td></tr>
<tr><td>14</td><td>14</td><td>atu_ats_trans_latency_2</td><td>0</td></tr>
<tr><td>15</td><td>15</td><td>atu_ats_trans_latency_3</td><td>0</td></tr>
<tr><td>16</td><td>16</td><td>atu_atucq_inval_cntr</td><td>0</td></tr>
<tr><td>17</td><td>17</td><td>atu_cache_evictions</td><td>0</td></tr>
<tr><td>18</td><td>18</td><td>atu_cache_hit_base_page_size_0</td><td>0</td></tr>
<tr><td>19</td><td>19</td><td>atu_cache_hit_base_page_size_1</td><td>0</td></tr>
<tr><td>20</td><td>20</td><td>atu_cache_hit_base_page_size_2</td><td>0</td></tr>
</table>
<h4>Interface 4</h4>
<table><tr><th>Rank</th><th>Metric ID</th><th>Metric Name</th><th>Diff</th></tr>
<tr><td>1</td><td>1</td><td>atu_ats_dynamic_state_change_cntr</td><td>0</td></tr>
<tr><td>2</td><td>2</td><td>atu_ats_inval_cntr</td><td>0</td></tr>
<tr><td>3</td><td>3</td><td>atu_ats_prs_odp_latency_0</td><td>0</td></tr>
<tr><td>4</td><td>4</td><td>atu_ats_prs_odp_latency_1</td><td>0</td></tr>
<tr><td>5</td><td>5</td><td>atu_ats_prs_odp_latency_2</td><td>0</td></tr>
<tr><td>6</td><td>6</td><td>atu_ats_prs_odp_latency_3</td><td>0</td></tr>
<tr><td>7</td><td>7</td><td>atu_at_stall_ccp</td><td>0</td></tr>
<tr><td>8</td><td>8</td><td>atu_at_stall_no_ptid</td><td>0</td></tr>
<tr><td>9</td><td>9</td><td>atu_at_stall_np_cdts</td><td>0</td></tr>
<tr><td>10</td><td>10</td><td>atu_at_stall_tarb_arb</td><td>0</td></tr>
<tr><td>11</td><td>11</td><td>atu_ats_trans_err</td><td>0</td></tr>
<tr><td>12</td><td>12</td><td>atu_ats_trans_latency_0</td><td>0</td></tr>
<tr><td>13</td><td>13</td><td>atu_ats_trans_latency_1</td><td>0</td></tr>
<tr><td>14</td><td>14</td><td>atu_ats_trans_latency_2</td><td>0</td></tr>
<tr><td>15</td><td>15</td><td>atu_ats_trans_latency_3</td><td>0</td></tr>
<tr><td>16</td><td>16</td><td>atu_atucq_inval_cntr</td><td>0</td></tr>
<tr><td>17</td><td>17</td><td>atu_cache_evictions</td><td>0</td></tr>
<tr><td>18</td><td>18</td><td>atu_cache_hit_base_page_size_0</td><td>0</td></tr>
<tr><td>19</td><td>19</td><td>atu_cache_hit_base_page_size_1</td><td>0</td></tr>
<tr><td>20</td><td>20</td><td>atu_cache_hit_base_page_size_2</td><td>0</td></tr>
</table>
<h4>Interface 5</h4>
<table><tr><th>Rank</th><th>Metric ID</th><th>Metric Name</th><th>Diff</th></tr>
<tr><td>1</td><td>1</td><td>atu_ats_dynamic_state_change_cntr</td><td>0</td></tr>
<tr><td>2</td><td>2</td><td>atu_ats_inval_cntr</td><td>0</td></tr>
<tr><td>3</td><td>3</td><td>atu_ats_prs_odp_latency_0</td><td>0</td></tr>
<tr><td>4</td><td>4</td><td>atu_ats_prs_odp_latency_1</td><td>0</td></tr>
<tr><td>5</td><td>5</td><td>atu_ats_prs_odp_latency_2</td><td>0</td></tr>
<tr><td>6</td><td>6</td><td>atu_ats_prs_odp_latency_3</td><td>0</td></tr>
<tr><td>7</td><td>7</td><td>atu_at_stall_ccp</td><td>0</td></tr>
<tr><td>8</td><td>8</td><td>atu_at_stall_no_ptid</td><td>0</td></tr>
<tr><td>9</td><td>9</td><td>atu_at_stall_np_cdts</td><td>0</td></tr>
<tr><td>10</td><td>10</td><td>atu_at_stall_tarb_arb</td><td>0</td></tr>
<tr><td>11</td><td>11</td><td>atu_ats_trans_err</td><td>0</td></tr>
<tr><td>12</td><td>12</td><td>atu_ats_trans_latency_0</td><td>0</td></tr>
<tr><td>13</td><td>13</td><td>atu_ats_trans_latency_1</td><td>0</td></tr>
<tr><td>14</td><td>14</td><td>atu_ats_trans_latency_2</td><td>0</td></tr>
<tr><td>15</td><td>15</td><td>atu_ats_trans_latency_3</td><td>0</td></tr>
<tr><td>16</td><td>16</td><td>atu_atucq_inval_cntr</td><td>0</td></tr>
<tr><td>17</td><td>17</td><td>atu_cache_evictions</td><td>0</td></tr>
<tr><td>18</td><td>18</td><td>atu_cache_hit_base_page_size_0</td><td>0</td></tr>
<tr><td>19</td><td>19</td><td>atu_cache_hit_base_page_size_1</td><td>0</td></tr>
<tr><td>20</td><td>20</td><td>atu_cache_hit_base_page_size_2</td><td>0</td></tr>
</table>
<h4>Interface 6</h4>
<table><tr><th>Rank</th><th>Metric ID</th><th>Metric Name</th><th>Diff</th></tr>
<tr><td>1</td><td>1</td><td>atu_ats_dynamic_state_change_cntr</td><td>0</td></tr>
<tr><td>2</td><td>2</td><td>atu_ats_inval_cntr</td><td>0</td></tr>
<tr><td>3</td><td>3</td><td>atu_ats_prs_odp_latency_0</td><td>0</td></tr>
<tr><td>4</td><td>4</td><td>atu_ats_prs_odp_latency_1</td><td>0</td></tr>
<tr><td>5</td><td>5</td><td>atu_ats_prs_odp_latency_2</td><td>0</td></tr>
<tr><td>6</td><td>6</td><td>atu_ats_prs_odp_latency_3</td><td>0</td></tr>
<tr><td>7</td><td>7</td><td>atu_at_stall_ccp</td><td>0</td></tr>
<tr><td>8</td><td>8</td><td>atu_at_stall_no_ptid</td><td>0</td></tr>
<tr><td>9</td><td>9</td><td>atu_at_stall_np_cdts</td><td>0</td></tr>
<tr><td>10</td><td>10</td><td>atu_at_stall_tarb_arb</td><td>0</td></tr>
<tr><td>11</td><td>11</td><td>atu_ats_trans_err</td><td>0</td></tr>
<tr><td>12</td><td>12</td><td>atu_ats_trans_latency_0</td><td>0</td></tr>
<tr><td>13</td><td>13</td><td>atu_ats_trans_latency_1</td><td>0</td></tr>
<tr><td>14</td><td>14</td><td>atu_ats_trans_latency_2</td><td>0</td></tr>
<tr><td>15</td><td>15</td><td>atu_ats_trans_latency_3</td><td>0</td></tr>
<tr><td>16</td><td>16</td><td>atu_atucq_inval_cntr</td><td>0</td></tr>
<tr><td>17</td><td>17</td><td>atu_cache_evictions</td><td>0</td></tr>
<tr><td>18</td><td>18</td><td>atu_cache_hit_base_page_size_0</td><td>0</td></tr>
<tr><td>19</td><td>19</td><td>atu_cache_hit_base_page_size_1</td><td>0</td></tr>
<tr><td>20</td><td>20</td><td>atu_cache_hit_base_page_size_2</td><td>0</td></tr>
</table>
<h4>Interface 7</h4>
<table><tr><th>Rank</th><th>Metric ID</th><th>Metric Name</th><th>Diff</th></tr>
<tr><td>1</td><td>1</td><td>atu_ats_dynamic_state_change_cntr</td><td>0</td></tr>
<tr><td>2</td><td>2</td><td>atu_ats_inval_cntr</td><td>0</td></tr>
<tr><td>3</td><td>3</td><td>atu_ats_prs_odp_latency_0</td><td>0</td></tr>
<tr><td>4</td><td>4</td><td>atu_ats_prs_odp_latency_1</td><td>0</td></tr>
<tr><td>5</td><td>5</td><td>atu_ats_prs_odp_latency_2</td><td>0</td></tr>
<tr><td>6</td><td>6</td><td>atu_ats_prs_odp_latency_3</td><td>0</td></tr>
<tr><td>7</td><td>7</td><td>atu_at_stall_ccp</td><td>0</td></tr>
<tr><td>8</td><td>8</td><td>atu_at_stall_no_ptid</td><td>0</td></tr>
<tr><td>9</td><td>9</td><td>atu_at_stall_np_cdts</td><td>0</td></tr>
<tr><td>10</td><td>10</td><td>atu_at_stall_tarb_arb</td><td>0</td></tr>
<tr><td>11</td><td>11</td><td>atu_ats_trans_err</td><td>0</td></tr>
<tr><td>12</td><td>12</td><td>atu_ats_trans_latency_0</td><td>0</td></tr>
<tr><td>13</td><td>13</td><td>atu_ats_trans_latency_1</td><td>0</td></tr>
<tr><td>14</td><td>14</td><td>atu_ats_trans_latency_2</td><td>0</td></tr>
<tr><td>15</td><td>15</td><td>atu_ats_trans_latency_3</td><td>0</td></tr>
<tr><td>16</td><td>16</td><td>atu_atucq_inval_cntr</td><td>0</td></tr>
<tr><td>17</td><td>17</td><td>atu_cache_evictions</td><td>0</td></tr>
<tr><td>18</td><td>18</td><td>atu_cache_hit_base_page_size_0</td><td>0</td></tr>
<tr><td>19</td><td>19</td><td>atu_cache_hit_base_page_size_1</td><td>0</td></tr>
<tr><td>20</td><td>20</td><td>atu_cache_hit_base_page_size_2</td><td>0</td></tr>
</table>
<h4>Interface 8</h4>
<table><tr><th>Rank</th><th>Metric ID</th><th>Metric Name</th><th>Diff</th></tr>
<tr><td>1</td><td>1</td><td>atu_ats_dynamic_state_change_cntr</td><td>0</td></tr>
<tr><td>2</td><td>2</td><td>atu_ats_inval_cntr</td><td>0</td></tr>
<tr><td>3</td><td>3</td><td>atu_ats_prs_odp_latency_0</td><td>0</td></tr>
<tr><td>4</td><td>4</td><td>atu_ats_prs_odp_latency_1</td><td>0</td></tr>
<tr><td>5</td><td>5</td><td>atu_ats_prs_odp_latency_2</td><td>0</td></tr>
<tr><td>6</td><td>6</td><td>atu_ats_prs_odp_latency_3</td><td>0</td></tr>
<tr><td>7</td><td>7</td><td>atu_at_stall_ccp</td><td>0</td></tr>
<tr><td>8</td><td>8</td><td>atu_at_stall_no_ptid</td><td>0</td></tr>
<tr><td>9</td><td>9</td><td>atu_at_stall_np_cdts</td><td>0</td></tr>
<tr><td>10</td><td>10</td><td>atu_at_stall_tarb_arb</td><td>0</td></tr>
<tr><td>11</td><td>11</td><td>atu_ats_trans_err</td><td>0</td></tr>
<tr><td>12</td><td>12</td><td>atu_ats_trans_latency_0</td><td>0</td></tr>
<tr><td>13</td><td>13</td><td>atu_ats_trans_latency_1</td><td>0</td></tr>
<tr><td>14</td><td>14</td><td>atu_ats_trans_latency_2</td><td>0</td></tr>
<tr><td>15</td><td>15</td><td>atu_ats_trans_latency_3</td><td>0</td></tr>
<tr><td>16</td><td>16</td><td>atu_atucq_inval_cntr</td><td>0</td></tr>
<tr><td>17</td><td>17</td><td>atu_cache_evictions</td><td>0</td></tr>
<tr><td>18</td><td>18</td><td>atu_cache_hit_base_page_size_0</td><td>0</td></tr>
<tr><td>19</td><td>19</td><td>atu_cache_hit_base_page_size_1</td><td>0</td></tr>
<tr><td>20</td><td>20</td><td>atu_cache_hit_base_page_size_2</td><td>0</td></tr>
</table>
</details>
<h3>Important Metrics</h3>
<table><tr><th>Metric ID</th><th>Metric Name</th><th>Iface 1</th><th>Iface 2</th><th>Iface 3</th><th>Iface 4</th><th>Iface 5</th><th>Iface 6</th><th>Iface 7</th><th>Iface 8</th></tr>
<tr><td>17</td><td>atu_cache_evictions</td>
<td>100000</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr><td>18</td><td>atu_cache_hit_base_page_size_0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr><td>22</td><td>atu_cache_hit_derivative1_page_size_0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr><td>564</td><td>hni_rx_paused_0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr><td>565</td><td>hni_rx_paused_1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr><td>613</td><td>hni_tx_paused_0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr><td>614</td><td>hni_tx_paused_1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr><td>835</td><td>lpe_net_match_overflow_0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr><td>839</td><td>lpe_net_match_priority_0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr><td>869</td><td>lpe_rndzv_puts_0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr><td>873</td><td>lpe_rndzv_puts_offloaded_0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr><td>1597</td><td>parbs_tarb_pi_non_posted_blocked_cnt</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr><td>1598</td><td>parbs_tarb_pi_non_posted_pkts</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr><td>1599</td><td>parbs_tarb_pi_posted_blocked_cnt</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr><td>1600</td><td>parbs_tarb_pi_posted_pkts</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr><td>1724</td><td>pct_trs_rsp_nack_drops</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
</table>
<h2>Counter Groups Detail</h2>
<details><summary><strong>CxiPerfStats</strong> — Traffic Congestion Counter Group</summary>
<table><tr><th>ID #</th><th>Interface #</th><th>Counter Name</th><th>Value</th><th>Description</th></tr>
<tr><td>88</td><td>1</td><td>hni_rx_paused_2</td><td>0</td><td title="Number of cycles in which the pause is applied on the receive path for traffic class <n>; default classes are 0 for request and 1 for response. Indicates that the network is supplying data faster than this endpoint can consume it. Divide by 1E9 to determine the proportion of time paused.">Number of cycles in which the pause is applied on the receive path for traffic class <n>; default classes are 0 for request and 1 for response. Indicates that the network is supplying data faster than this endpoint can consume it. Divide by 1E9 to determine the proportion of time paused.</td></tr>
<tr><td>107</td><td>1</td><td>hni_tx_paused_5</td><td>0</td><td title="Number of cycles in which the transmit path is paused for traffic class <n>; default classes are 0 for request and 1 for response. Indicates that this endpoint is supplying data faster than the network can deliver it. Divide by 1E9 to determine the proportion of time paused.">Number of cycles in which the transmit path is paused for traffic class <n>; default classes are 0 for request and 1 for response. Indicates that this endpoint is supplying data faster than the network can deliver it. Divide by 1E9 to determine the proportion of time paused.</td></tr>
<tr><td>130</td><td>1</td><td>atu_cache_miss_1</td><td>0</td><td title="Number of misses in the NIC translation cache. Four counters of which counter 0 counts misses on 4K pages and counter 1 counts misses on 2M pages by default.">Number of misses in the NIC translation cache. Four counters of which counter 0 counts misses on 4K pages and counter 1 counts misses on 2M pages by default.</td></tr>
<tr><td>144</td><td>1</td><td>hni_pkts_sent_by_tc_7</td><td>0</td><td title="Number of packets sent in traffic class <n>; 8 counters, default classes are 0 for request and 1 for response.">Number of packets sent in traffic class <n>; 8 counters, default classes are 0 for request and 1 for response.</td></tr>
<tr><td>158</td><td>1</td><td>hni_rx_paused_3</td><td>0</td><td title="Number of cycles in which the pause is applied on the receive path for traffic class <n>; default classes are 0 for request and 1 for response. Indicates that the network is supplying data faster than this endpoint can consume it. Divide by 1E9 to determine the proportion of time paused.">Number of cycles in which the pause is applied on the receive path for traffic class <n>; default classes are 0 for request and 1 for response. Indicates that the network is supplying data faster than this endpoint can consume it. Divide by 1E9 to determine the proportion of time paused.</td></tr>
<tr><td>166</td><td>1</td><td>lpe_net_match_priority_1</td><td>0</td><td title="Number of messages matched on the priority list (or receive was posted before the message arrived). Four counters of which 0 is the default. These messages incur lower cost because data is written directly to the user buffer.">Number of messages matched on the priority list (or receive was posted before the message arrived). Four counters of which 0 is the default. These messages incur lower cost because data is written directly to the user buffer.</td></tr>
<tr><td>262</td><td>1</td><td>hni_rx_paused_4</td><td>0</td><td title="Number of cycles in which the pause is applied on the receive path for traffic class <n>; default classes are 0 for request and 1 for response. Indicates that the network is supplying data faster than this endpoint can consume it. Divide by 1E9 to determine the proportion of time paused.">Number of cycles in which the pause is applied on the receive path for traffic class <n>; default classes are 0 for request and 1 for response. Indicates that the network is supplying data faster than this endpoint can consume it. Divide by 1E9 to determine the proportion of time paused.</td></tr>
<tr><td>300</td><td>1</td><td>hni_pkts_sent_by_tc_5</td><td>0</td><td title="Number of packets sent in traffic class <n>; 8 counters, default classes are 0 for request and 1 for response.">Number of packets sent in traffic class <n>; 8 counters, default classes are 0 for request and 1 for response.</td></tr>
<tr><td>389</td><td>1</td><td>atu_cache_miss_0</td><td>0</td><td title="Number of misses in the NIC translation cache. Four counters of which counter 0 counts misses on 4K pages and counter 1 counts misses on 2M pages by default.">Number of misses in the NIC translation cache. Four counters of which counter 0 counts misses on 4K pages and counter 1 counts misses on 2M pages by default.</td></tr>
<tr><td>406</td><td>1</td><td>lpe_net_match_overflow_1</td><td>0</td><td title="Number of messages where payload data was delivered to a buffer on the overflow list because there was no match on the priority list. Four counters of which 0 is the default. These messages incur higher cost because data must be copied from the overflow buffer. Compute the ratio priority/(priority + overflow) to determine the porportion of messages for which receives were posted in advance.">Number of messages where payload data was delivered to a buffer on the overflow list because there was no match on the priority list. Four counters of which 0 is the default. These messages incur higher cost because data must be copied from the overflow buffer. Compute the ratio priority/(priority + overflow) to determine the porportion of messages for which receives were posted in advance.</td></tr>
<tr><td>495</td><td>1</td><td>atu_cache_miss_2</td><td>0</td><td title="Number of misses in the NIC translation cache. Four counters of which counter 0 counts misses on 4K pages and counter 1 counts misses on 2M pages by default.">Number of misses in the NIC translation cache. Four counters of which counter 0 counts misses on 4K pages and counter 1 counts misses on 2M pages by default.</td></tr>
<tr><td>529</td><td>1</td><td>hni_tx_paused_3</td><td>0</td><td title="Number of cycles in which the transmit path is paused for traffic class <n>; default classes are 0 for request and 1 for response. Indicates that this endpoint is supplying data faster than the network can deliver it. Divide by 1E9 to determine the proportion of time paused.">Number of cycles in which the transmit path is paused for traffic class <n>; default classes are 0 for request and 1 for response. Indicates that this endpoint is supplying data faster than the network can deliver it. Divide by 1E9 to determine the proportion of time paused.</td></tr>
<tr><td>536</td><td>1</td><td>hni_pkts_recv_by_tc_0</td><td>0</td><td title="Number of packets received in traffic class <n>; 8 counters, default classes are 0 for request and 1 for response.">Number of packets received in traffic class <n>; 8 counters, default classes are 0 for request and 1 for response.</td></tr>
<tr><td>578</td><td>1</td><td>lpe_net_match_priority_2</td><td>0</td><td title="Number of messages matched on the priority list (or receive was posted before the message arrived). Four counters of which 0 is the default. These messages incur lower cost because data is written directly to the user buffer.">Number of messages matched on the priority list (or receive was posted before the message arrived). Four counters of which 0 is the default. These messages incur lower cost because data is written directly to the user buffer.</td></tr>
<tr><td>594</td><td>1</td><td>hni_pkts_recv_by_tc_7</td><td>0</td><td title="Number of packets received in traffic class <n>; 8 counters, default classes are 0 for request and 1 for response.">Number of packets received in traffic class <n>; 8 counters, default classes are 0 for request and 1 for response.</td></tr>
<tr><td>598</td><td>1</td><td>hni_rx_paused_0</td><td>0</td><td title="Number of cycles in which the pause is applied on the receive path for traffic class <n>; default classes are 0 for request and 1 for response. Indicates that the network is supplying data faster than this endpoint can consume it. Divide by 1E9 to determine the proportion of time paused.">Number of cycles in which the pause is applied on the receive path for traffic class <n>; default classes are 0 for request and 1 for response. Indicates that the network is supplying data faster than this endpoint can consume it. Divide by 1E9 to determine the proportion of time paused.</td></tr>
<tr><td>648</td><td>1</td><td>hni_rx_paused_6</td><td>0</td><td title="Number of cycles in which the pause is applied on the receive path for traffic class <n>; default classes are 0 for request and 1 for response. Indicates that the network is supplying data faster than this endpoint can consume it. Divide by 1E9 to determine the proportion of time paused.">Number of cycles in which the pause is applied on the receive path for traffic class <n>; default classes are 0 for request and 1 for response. Indicates that the network is supplying data faster than this endpoint can consume it. Divide by 1E9 to determine the proportion of time paused.</td></tr>
<tr><td>668</td><td>1</td><td>atu_cache_miss_3</td><td>0</td><td title="Number of misses in the NIC translation cache. Four counters of which counter 0 counts misses on 4K pages and counter 1 counts misses on 2M pages by default.">Number of misses in the NIC translation cache. Four counters of which counter 0 counts misses on 4K pages and counter 1 counts misses on 2M pages by default.</td></tr>
<tr><td>688</td><td>1</td><td>hni_rx_paused_1</td><td>0</td><td title="Number of cycles in which the pause is applied on the receive path for traffic class <n>; default classes are 0 for request and 1 for response. Indicates that the network is supplying data faster than this endpoint can consume it. Divide by 1E9 to determine the proportion of time paused.">Number of cycles in which the pause is applied on the receive path for traffic class <n>; default classes are 0 for request and 1 for response. Indicates that the network is supplying data faster than this endpoint can consume it. Divide by 1E9 to determine the proportion of time paused.</td></tr>
<tr><td>690</td><td>1</td><td>hni_pkts_sent_by_tc_6</td><td>0</td><td title="Number of packets sent in traffic class <n>; 8 counters, default classes are 0 for request and 1 for response.">Number of packets sent in traffic class <n>; 8 counters, default classes are 0 for request and 1 for response.</td></tr>
<tr><td>720</td><td>1</td><td>hni_pkts_recv_by_tc_1</td><td>0</td><td title="Number of packets received in traffic class <n>; 8 counters, default classes are 0 for request and 1 for response.">Number of packets received in traffic class <n>; 8 counters, default classes are 0 for request and 1 for response.</td></tr>
<tr><td>790</td><td>1</td><td>parbs_tarb_pi_non_posted_blocked_cnt</td><td>0</td><td title="reads), and the number of cycles in which this path is blocked. Compute the ratio cycles/pkts. Values of more than a few cycles per packet indicate per host performance (high read latencies). This endpoint is likely to be injecting at a low rate.">reads), and the number of cycles in which this path is blocked. Compute the ratio cycles/pkts. Values of more than a few cycles per packet indicate per host performance (high read latencies). This endpoint is likely to be injecting at a low rate.</td></tr>
<tr><td>811</td><td>1</td><td>hni_pkts_recv_by_tc_5</td><td>0</td><td title="Number of packets received in traffic class <n>; 8 counters, default classes are 0 for request and 1 for response.">Number of packets received in traffic class <n>; 8 counters, default classes are 0 for request and 1 for response.</td></tr>
<tr><td>884</td><td>1</td><td>hni_pkts_sent_by_tc_3</td><td>0</td><td title="Number of packets sent in traffic class <n>; 8 counters, default classes are 0 for request and 1 for response.">Number of packets sent in traffic class <n>; 8 counters, default classes are 0 for request and 1 for response.</td></tr>
<tr><td>896</td><td>1</td><td>hni_tx_paused_7</td><td>0</td><td title="Number of cycles in which the transmit path is paused for traffic class <n>; default classes are 0 for request and 1 for response. Indicates that this endpoint is supplying data faster than the network can deliver it. Divide by 1E9 to determine the proportion of time paused.">Number of cycles in which the transmit path is paused for traffic class <n>; default classes are 0 for request and 1 for response. Indicates that this endpoint is supplying data faster than the network can deliver it. Divide by 1E9 to determine the proportion of time paused.</td></tr>
<tr><td>947</td><td>1</td><td>parbs_tarb_pi_posted_blocked_cnt</td><td>0</td><td title="and the number of cycles in which this path is blocked. Compute the ratio cycles/pkts. Values of more than a few cycles per packet indicate back pressure from the host. This endpoint is likely to be the cause of congestion.">and the number of cycles in which this path is blocked. Compute the ratio cycles/pkts. Values of more than a few cycles per packet indicate back pressure from the host. This endpoint is likely to be the cause of congestion.</td></tr>
<tr><td>949</td><td>1</td><td>lpe_net_match_priority_0</td><td>0</td><td title="Number of messages matched on the priority list (or receive was posted before the message arrived). Four counters of which 0 is the default. These messages incur lower cost because data is written directly to the user buffer.">Number of messages matched on the priority list (or receive was posted before the message arrived). Four counters of which 0 is the default. These messages incur lower cost because data is written directly to the user buffer.</td></tr>
<tr><td>966</td><td>1</td><td>hni_rx_paused_5</td><td>0</td><td title="Number of cycles in which the pause is applied on the receive path for traffic class <n>; default classes are 0 for request and 1 for response. Indicates that the network is supplying data faster than this endpoint can consume it. Divide by 1E9 to determine the proportion of time paused.">Number of cycles in which the pause is applied on the receive path for traffic class <n>; default classes are 0 for request and 1 for response. Indicates that the network is supplying data faster than this endpoint can consume it. Divide by 1E9 to determine the proportion of time paused.</td></tr>
<tr><td>970</td><td>1</td><td>hni_pkts_recv_by_tc_6</td><td>0</td><td title="Number of packets received in traffic class <n>; 8 counters, default classes are 0 for request and 1 for response.">Number of packets received in traffic class <n>; 8 counters, default classes are 0 for request and 1 for response.</td></tr>
<tr><td>1018</td><td>1</td><td>lpe_net_match_overflow_0</td><td>0</td><td title="Number of messages where payload data was delivered to a buffer on the overflow list because there was no match on the priority list. Four counters of which 0 is the default. These messages incur higher cost because data must be copied from the overflow buffer. Compute the ratio priority/(priority + overflow) to determine the porportion of messages for which receives were posted in advance.">Number of messages where payload data was delivered to a buffer on the overflow list because there was no match on the priority list. Four counters of which 0 is the default. These messages incur higher cost because data must be copied from the overflow buffer. Compute the ratio priority/(priority + overflow) to determine the porportion of messages for which receives were posted in advance.</td></tr>
<tr><td>1042</td><td>1</td><td>lpe_net_match_overflow_3</td><td>0</td><td title="Number of messages where payload data was delivered to a buffer on the overflow list because there was no match on the priority list. Four counters of which 0 is the default. These messages incur higher cost because data must be copied from the overflow buffer. Compute the ratio priority/(priority + overflow) to determine the porportion of messages for which receives were posted in advance.">Number of messages where payload data was delivered to a buffer on the overflow list because there was no match on the priority list. Four counters of which 0 is the default. These messages incur higher cost because data must be copied from the overflow buffer. Compute the ratio priority/(priority + overflow) to determine the porportion of messages for which receives were posted in advance.</td></tr>
<tr><td>1164</td><td>1</td><td>hni_rx_paused_7</td><td>0</td><td title="Number of cycles in which the pause is applied on the receive path for traffic class <n>; default classes are 0 for request and 1 for response. Indicates that the network is supplying data faster than this endpoint can consume it. Divide by 1E9 to determine the proportion of time paused.">Number of cycles in which the pause is applied on the receive path for traffic class <n>; default classes are 0 for request and 1 for response. Indicates that the network is supplying data faster than this endpoint can consume it. Divide by 1E9 to determine the proportion of time paused.</td></tr>
<tr><td>1175</td><td>1</td><td>hni_pkts_sent_by_tc_2</td><td>0</td><td title="Number of packets sent in traffic class <n>; 8 counters, default classes are 0 for request and 1 for response.">Number of packets sent in traffic class <n>; 8 counters, default classes are 0 for request and 1 for response.</td></tr>
<tr><td>1261</td><td>1</td><td>lpe_net_match_priority_3</td><td>0</td><td title="Number of messages matched on the priority list (or receive was posted before the message arrived). Four counters of which 0 is the default. These messages incur lower cost because data is written directly to the user buffer.">Number of messages matched on the priority list (or receive was posted before the message arrived). Four counters of which 0 is the default. These messages incur lower cost because data is written directly to the user buffer.</td></tr>
<tr><td>1329</td><td>1</td><td>hni_pkts_sent_by_tc_0</td><td>0</td><td title="Number of packets sent in traffic class <n>; 8 counters, default classes are 0 for request and 1 for response.">Number of packets sent in traffic class <n>; 8 counters, default classes are 0 for request and 1 for response.</td></tr>
<tr><td>1330</td><td>1</td><td>hni_tx_paused_0</td><td>0</td><td title="Number of cycles in which the transmit path is paused for traffic class <n>; default classes are 0 for request and 1 for response. Indicates that this endpoint is supplying data faster than the network can deliver it. Divide by 1E9 to determine the proportion of time paused.">Number of cycles in which the transmit path is paused for traffic class <n>; default classes are 0 for request and 1 for response. Indicates that this endpoint is supplying data faster than the network can deliver it. Divide by 1E9 to determine the proportion of time paused.</td></tr>
<tr><td>1366</td><td>1</td><td>parbs_tarb_pi_non_posted_pkts</td><td>0</td><td title="Number of PCIe packets transferred using the non-posted path (for example,">Number of PCIe packets transferred using the non-posted path (for example,</td></tr>
<tr><td>1370</td><td>1</td><td>hni_tx_paused_1</td><td>0</td><td title="Number of cycles in which the transmit path is paused for traffic class <n>; default classes are 0 for request and 1 for response. Indicates that this endpoint is supplying data faster than the network can deliver it. Divide by 1E9 to determine the proportion of time paused.">Number of cycles in which the transmit path is paused for traffic class <n>; default classes are 0 for request and 1 for response. Indicates that this endpoint is supplying data faster than the network can deliver it. Divide by 1E9 to determine the proportion of time paused.</td></tr>
<tr><td>1459</td><td>1</td><td>hni_tx_paused_2</td><td>0</td><td title="Number of cycles in which the transmit path is paused for traffic class <n>; default classes are 0 for request and 1 for response. Indicates that this endpoint is supplying data faster than the network can deliver it. Divide by 1E9 to determine the proportion of time paused.">Number of cycles in which the transmit path is paused for traffic class <n>; default classes are 0 for request and 1 for response. Indicates that this endpoint is supplying data faster than the network can deliver it. Divide by 1E9 to determine the proportion of time paused.</td></tr>
<tr><td>1475</td><td>1</td><td>hni_pkts_recv_by_tc_2</td><td>0</td><td title="Number of packets received in traffic class <n>; 8 counters, default classes are 0 for request and 1 for response.">Number of packets received in traffic class <n>; 8 counters, default classes are 0 for request and 1 for response.</td></tr>
<tr><td>1508</td><td>1</td><td>hni_tx_paused_4</td><td>0</td><td title="Number of cycles in which the transmit path is paused for traffic class <n>; default classes are 0 for request and 1 for response. Indicates that this endpoint is supplying data faster than the network can deliver it. Divide by 1E9 to determine the proportion of time paused.">Number of cycles in which the transmit path is paused for traffic class <n>; default classes are 0 for request and 1 for response. Indicates that this endpoint is supplying data faster than the network can deliver it. Divide by 1E9 to determine the proportion of time paused.</td></tr>
<tr><td>1620</td><td>1</td><td>lpe_net_match_overflow_2</td><td>0</td><td title="Number of messages where payload data was delivered to a buffer on the overflow list because there was no match on the priority list. Four counters of which 0 is the default. These messages incur higher cost because data must be copied from the overflow buffer. Compute the ratio priority/(priority + overflow) to determine the porportion of messages for which receives were posted in advance.">Number of messages where payload data was delivered to a buffer on the overflow list because there was no match on the priority list. Four counters of which 0 is the default. These messages incur higher cost because data must be copied from the overflow buffer. Compute the ratio priority/(priority + overflow) to determine the porportion of messages for which receives were posted in advance.</td></tr>
<tr><td>1709</td><td>1</td><td>hni_pkts_sent_by_tc_4</td><td>0</td><td title="Number of packets sent in traffic class <n>; 8 counters, default classes are 0 for request and 1 for response.">Number of packets sent in traffic class <n>; 8 counters, default classes are 0 for request and 1 for response.</td></tr>
<tr><td>1710</td><td>1</td><td>hni_tx_paused_6</td><td>0</td><td title="Number of cycles in which the transmit path is paused for traffic class <n>; default classes are 0 for request and 1 for response. Indicates that this endpoint is supplying data faster than the network can deliver it. Divide by 1E9 to determine the proportion of time paused.">Number of cycles in which the transmit path is paused for traffic class <n>; default classes are 0 for request and 1 for response. Indicates that this endpoint is supplying data faster than the network can deliver it. Divide by 1E9 to determine the proportion of time paused.</td></tr>
<tr><td>1775</td><td>1</td><td>hni_pkts_sent_by_tc_1</td><td>0</td><td title="Number of packets sent in traffic class <n>; 8 counters, default classes are 0 for request and 1 for response.">Number of packets sent in traffic class <n>; 8 counters, default classes are 0 for request and 1 for response.</td></tr>
<tr><td>1798</td><td>1</td><td>parbs_tarb_pi_posted_pkts</td><td>0</td><td title="Number of PCIe packets transferred using the posted path (for example, writes),">Number of PCIe packets transferred using the posted path (for example, writes),</td></tr>
<tr><td>1832</td><td>1</td><td>hni_pkts_recv_by_tc_3</td><td>0</td><td title="Number of packets received in traffic class <n>; 8 counters, default classes are 0 for request and 1 for response.">Number of packets received in traffic class <n>; 8 counters, default classes are 0 for request and 1 for response.</td></tr>
<tr><td>1875</td><td>1</td><td>hni_pkts_recv_by_tc_4</td><td>0</td><td title="Number of packets received in traffic class <n>; 8 counters, default classes are 0 for request and 1 for response.">Number of packets received in traffic class <n>; 8 counters, default classes are 0 for request and 1 for response.</td></tr>
</table></details>
<details><summary><strong>CxiErrStats</strong> — Network Error Counter Group</summary>
<table><tr><th>ID #</th><th>Interface #</th><th>Counter Name</th><th>Value</th><th>Description</th></tr>
<tr><td>22</td><td>1</td><td>pct_trs_rsp_nack_drops</td><td>0</td><td title="Number of NACKs dropped. Retry handler is invoked.">Number of NACKs dropped. Retry handler is invoked.</td></tr>
<tr><td>186</td><td>1</td><td>pct_spt_timeouts</td><td>0</td><td title="Number of response timeouts (or packet loss in the network).">Number of response timeouts (or packet loss in the network).</td></tr>
<tr><td>614</td><td>1</td><td>pct_sct_timeouts</td><td>0</td><td title="Retry handler is invoked.">Retry handler is invoked.</td></tr>
<tr><td>680</td><td>1</td><td>hni_llr_tx_replay_event</td><td>0</td><td title="Number of LLR replays. High rates (multiple per second) indicate that the LLR">Number of LLR replays. High rates (multiple per second) indicate that the LLR</td></tr>
<tr><td>973</td><td>1</td><td>hni_pcs_uncorrected_cw</td><td>0</td><td title="Number of uncorrected code words received on the switch to NIC link. High rates (multiple errors per second) indicate a poor quality link.">Number of uncorrected code words received on the switch to NIC link. High rates (multiple errors per second) indicate a poor quality link.</td></tr>
<tr><td>981</td><td>1</td><td>pct_no_mst_nacks</td><td>0</td><td title="NO_DESCRIPTION">NO_DESCRIPTION</td></tr>
<tr><td>1321</td><td>1</td><td>pct_no_tct_nacks</td><td>0</td><td title="Number of resource exhaustion NACKs. Retry handler is invoked.">Number of resource exhaustion NACKs. Retry handler is invoked.</td></tr>
<tr><td>1327</td><td>1</td><td>pct_no_trs_nacks</td><td>0</td><td title="NO_DESCRIPTION">NO_DESCRIPTION</td></tr>
<tr><td>1702</td><td>1</td><td>pct_retry_srb_requests</td><td>0</td><td title="Number of retries.">Number of retries.</td></tr>
<tr><td>1891</td><td>1</td><td>hni_llr_rx_replay_event</td><td>0</td><td title="mechanism is providing protection on a poor quality link.">mechanism is providing protection on a poor quality link.</td></tr>
</table></details>
<details><summary><strong>CxiOpCommands</strong> — Operation (Command) Counter Group</summary>
<table><tr><th>ID #</th><th>Interface #</th><th>Counter Name</th><th>Value</th><th>Description</th></tr>
</table></details>
<details><summary><strong>CxiOpPackets</strong> — Operation (Packet) Counter Group</summary>
<table><tr><th>ID #</th><th>Interface #</th><th>Counter Name</th><th>Value</th><th>Description</th></tr>
<tr><td>83</td><td>1</td><td>hni_rx_ok_128_to_255</td><td>0</td><td title="Number of packets received in each of 12 size bins.">Number of packets received in each of 12 size bins.</td></tr>
<tr><td>204</td><td>1</td><td>hni_tx_ok_512_to_1023</td><td>0</td><td title="Number of packets sent in each of 12 size bins: - Small packets 27, 35, 64 bytes - 65-128, 256-511, 512-1023, 1024-2047, 2048-4095, 4096-8191, 8192-Max">Number of packets sent in each of 12 size bins: - Small packets 27, 35, 64 bytes - 65-128, 256-511, 512-1023, 1024-2047, 2048-4095, 4096-8191, 8192-Max</td></tr>
<tr><td>248</td><td>1</td><td>hni_tx_ok_4096_to_8191</td><td>0</td><td title="Number of packets sent in each of 12 size bins: - Small packets 27, 35, 64 bytes - 65-128, 256-511, 512-1023, 1024-2047, 2048-4095, 4096-8191, 8192-Max">Number of packets sent in each of 12 size bins: - Small packets 27, 35, 64 bytes - 65-128, 256-511, 512-1023, 1024-2047, 2048-4095, 4096-8191, 8192-Max</td></tr>
<tr><td>327</td><td>1</td><td>hni_tx_ok_256_to_511</td><td>0</td><td title="Number of packets sent in each of 12 size bins: - Small packets 27, 35, 64 bytes - 65-128, 256-511, 512-1023, 1024-2047, 2048-4095, 4096-8191, 8192-Max">Number of packets sent in each of 12 size bins: - Small packets 27, 35, 64 bytes - 65-128, 256-511, 512-1023, 1024-2047, 2048-4095, 4096-8191, 8192-Max</td></tr>
<tr><td>784</td><td>1</td><td>hni_tx_ok_36_to_63</td><td>0</td><td title="Number of packets sent in each of 12 size bins: - Small packets 27, 35, 64 bytes - 65-128, 256-511, 512-1023, 1024-2047, 2048-4095, 4096-8191, 8192-Max">Number of packets sent in each of 12 size bins: - Small packets 27, 35, 64 bytes - 65-128, 256-511, 512-1023, 1024-2047, 2048-4095, 4096-8191, 8192-Max</td></tr>
<tr><td>950</td><td>1</td><td>hni_rx_ok_1024_to_2047</td><td>0</td><td title="Number of packets received in each of 12 size bins.">Number of packets received in each of 12 size bins.</td></tr>
<tr><td>985</td><td>1</td><td>hni_rx_ok_2048_to_4095</td><td>0</td><td title="Number of packets received in each of 12 size bins.">Number of packets received in each of 12 size bins.</td></tr>
<tr><td>1011</td><td>1</td><td>hni_tx_ok_65_to_127</td><td>0</td><td title="Number of packets sent in each of 12 size bins: - Small packets 27, 35, 64 bytes - 65-128, 256-511, 512-1023, 1024-2047, 2048-4095, 4096-8191, 8192-Max">Number of packets sent in each of 12 size bins: - Small packets 27, 35, 64 bytes - 65-128, 256-511, 512-1023, 1024-2047, 2048-4095, 4096-8191, 8192-Max</td></tr>
<tr><td>1120</td><td>1</td><td>hni_tx_ok_128_to_255</td><td>0</td><td title="Number of packets sent in each of 12 size bins: - Small packets 27, 35, 64 bytes - 65-128, 256-511, 512-1023, 1024-2047, 2048-4095, 4096-8191, 8192-Max">Number of packets sent in each of 12 size bins: - Small packets 27, 35, 64 bytes - 65-128, 256-511, 512-1023, 1024-2047, 2048-4095, 4096-8191, 8192-Max</td></tr>
<tr><td>1189</td><td>1</td><td>hni_rx_ok_4096_to_8191</td><td>0</td><td title="Number of packets received in each of 12 size bins.">Number of packets received in each of 12 size bins.</td></tr>
<tr><td>1285</td><td>1</td><td>hni_rx_ok_256_to_511</td><td>0</td><td title="Number of packets received in each of 12 size bins.">Number of packets received in each of 12 size bins.</td></tr>
<tr><td>1301</td><td>1</td><td>hni_rx_ok_512_to_1023</td><td>0</td><td title="Number of packets received in each of 12 size bins.">Number of packets received in each of 12 size bins.</td></tr>
<tr><td>1379</td><td>1</td><td>hni_rx_ok_65_to_127</td><td>0</td><td title="Number of packets received in each of 12 size bins.">Number of packets received in each of 12 size bins.</td></tr>
<tr><td>1428</td><td>1</td><td>hni_tx_ok_1024_to_2047</td><td>0</td><td title="Number of packets sent in each of 12 size bins: - Small packets 27, 35, 64 bytes - 65-128, 256-511, 512-1023, 1024-2047, 2048-4095, 4096-8191, 8192-Max">Number of packets sent in each of 12 size bins: - Small packets 27, 35, 64 bytes - 65-128, 256-511, 512-1023, 1024-2047, 2048-4095, 4096-8191, 8192-Max</td></tr>
<tr><td>1577</td><td>1</td><td>hni_rx_ok_36_to_63</td><td>0</td><td title="Number of packets received in each of 12 size bins.">Number of packets received in each of 12 size bins.</td></tr>
<tr><td>1727</td><td>1</td><td>hni_tx_ok_2048_to_4095</td><td>0</td><td title="Number of packets sent in each of 12 size bins: - Small packets 27, 35, 64 bytes - 65-128, 256-511, 512-1023, 1024-2047, 2048-4095, 4096-8191, 8192-Max">Number of packets sent in each of 12 size bins: - Small packets 27, 35, 64 bytes - 65-128, 256-511, 512-1023, 1024-2047, 2048-4095, 4096-8191, 8192-Max</td></tr>
</table></details>
<details><summary><strong>CxiDmaEngine</strong> — DMA Engine Counter Group</summary>
<table><tr><th>ID #</th><th>Interface #</th><th>Counter Name</th><th>Value</th><th>Description</th></tr>
<tr><td>310</td><td>1</td><td>oxe_channel_idle</td><td>0</td><td title="Number of cycles in which available bandwidth is not used.">Number of cycles in which available bandwidth is not used.</td></tr>
<tr><td>669</td><td>1</td><td>ixe_dmawr_stall_p_cdt</td><td>0</td><td title="Number of stalls due to no posted credits (cycles).">Number of stalls due to no posted credits (cycles).</td></tr>
<tr><td>786</td><td>1</td><td>ixe_disp_dmawr_reqs</td><td>0</td><td title="Number of requests to DMA write controller.">Number of requests to DMA write controller.</td></tr>
<tr><td>908</td><td>1</td><td>pi_pti_tarb_mrd_pkts</td><td>0</td><td title="Number of memory read TLPs (all source).">Number of memory read TLPs (all source).</td></tr>
<tr><td>1217</td><td>1</td><td>ixe_dmawr_stall_np_cdt</td><td>0</td><td title="Number of stalls due to no non-posted credits (cycles).">Number of stalls due to no non-posted credits (cycles).</td></tr>
<tr><td>1237</td><td>1</td><td>pi_pti_tarb_mwr_pkts</td><td>0</td><td title="Number of memory write TLPs (all source).">Number of memory write TLPs (all source).</td></tr>
</table></details>
<details><summary><strong>CxiWritesToHost</strong> — Writes-to-Host Counter Group</summary>
<table><tr><th>ID #</th><th>Interface #</th><th>Counter Name</th><th>Value</th><th>Description</th></tr>
</table></details>
<details><summary><strong>CxiMessageMatchingPooled</strong> — Message Matching of Pooled Counters</summary>
<table><tr><th>ID #</th><th>Interface #</th><th>Counter Name</th><th>Value</th><th>Description</th></tr>
<tr><td>567</td><td>1</td><td>lpe_famo_cmds</td><td>0</td><td title="Number of fetching AMO commands received by LPE.">Number of fetching AMO commands received by LPE.</td></tr>
<tr><td>1564</td><td>1</td><td>lpe_amo_cmds</td><td>0</td><td title="Number of non-fetching AMO commands received by LPE.">Number of non-fetching AMO commands received by LPE.</td></tr>
</table></details>
<details><summary><strong>CxiTranslationUnit</strong> — Translation Unit Counter Group</summary>
<table><tr><th>ID #</th><th>Interface #</th><th>Counter Name</th><th>Value</th><th>Description</th></tr>
<tr><td>175</td><td>1</td><td>atu_cache_miss_ixe</td><td>0</td><td title="NO_DESCRIPTION">NO_DESCRIPTION</td></tr>
<tr><td>451</td><td>1</td><td>atu_client_req_ee</td><td>0</td><td title="Number of translation requests by client (events, writes, reads).">Number of translation requests by client (events, writes, reads).</td></tr>
<tr><td>892</td><td>1</td><td>atu_client_req_ixe</td><td>0</td><td title="NO_DESCRIPTION">NO_DESCRIPTION</td></tr>
<tr><td>924</td><td>1</td><td>atu_cache_evictions</td><td>0</td><td title="Number of times a tag was evicted from the NIC translation cache to make room for a new tag.">Number of times a tag was evicted from the NIC translation cache to make room for a new tag.</td></tr>
<tr><td>1017</td><td>1</td><td>atu_client_req_oxe</td><td>0</td><td title="Note that EE is the Event Engine; IXE is the Input Transfer Engine or Writes; and OXE is the Output Transfer Engine or Reads.">Note that EE is the Event Engine; IXE is the Input Transfer Engine or Writes; and OXE is the Output Transfer Engine or Reads.</td></tr>
<tr><td>1224</td><td>1</td><td>atu_cache_miss_ee</td><td>0</td><td title="Number of cache misses by client (events, writes, reads).">Number of cache misses by client (events, writes, reads).</td></tr>
<tr><td>1689</td><td>1</td><td>atu_cache_miss_oxe</td><td>0</td><td title="NO_DESCRIPTION">NO_DESCRIPTION</td></tr>
</table></details>
<details><summary><strong>CxiLatencyHist</strong> — Latency Histogram Counter Group</summary>
<table><tr><th>ID #</th><th>Interface #</th><th>Counter Name</th><th>Value</th><th>Description</th></tr>
</table></details>
<details><summary><strong>CxiPctReqRespTracking</strong> — PCT Request & Response Tracking Counter Group</summary>
<table><tr><th>ID #</th><th>Interface #</th><th>Counter Name</th><th>Value</th><th>Description</th></tr>
<tr><td>56</td><td>1</td><td>pct_req_unordered</td><td>0</td><td title="Number of unordered requests.">Number of unordered requests.</td></tr>
<tr><td>729</td><td>1</td><td>pct_req_ordered</td><td>0</td><td title="Number of ordered requests.">Number of ordered requests.</td></tr>
<tr><td>963</td><td>1</td><td>pct_responses_received</td><td>0</td><td title="Number of responses received (all unordered).">Number of responses received (all unordered).</td></tr>
<tr><td>1705</td><td>1</td><td>pct_conn_sct_open</td><td>0</td><td title="Number of open requests.">Number of open requests.</td></tr>
</table></details>
<details><summary><strong>CxiLinkReliability</strong> — Link Reliability Counter Group</summary>
<table><tr><th>ID #</th><th>Interface #</th><th>Counter Name</th><th>Value</th><th>Description</th></tr>
<tr><td>607</td><td>1</td><td>hni_pcs_good_cw</td><td>0</td><td title="Number of codewords received with no errors.">Number of codewords received with no errors.</td></tr>
<tr><td>733</td><td>1</td><td>hni_pcs_corrected_cw</td><td>0</td><td title="Number of corrected codewords.">Number of corrected codewords.</td></tr>
</table></details>
<details><summary><strong>CxiCongestion</strong> — Congestion Counter Group</summary>
<table><tr><th>ID #</th><th>Interface #</th><th>Counter Name</th><th>Value</th><th>Description</th></tr>
<tr><td>1525</td><td>1</td><td>hni_rx_paused_std</td><td>0</td><td title="Number of cycles in which at least one PCP pause occurred.">Number of cycles in which at least one PCP pause occurred.</td></tr>
</table></details>
</body></html>